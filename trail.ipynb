{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import sys\r\n",
    "\r\n",
    "from numpy import isin\r\n",
    "# from torch._C import device\r\n",
    "import utils\r\n",
    "import argparse\r\n",
    "import torch.nn as nn\r\n",
    "import torch.utils\r\n",
    "import torchvision.datasets as dset\r\n",
    "import torch\r\n",
    "if torch.cuda.is_available():\r\n",
    "    import torch.backends.cudnn as cudnn\r\n",
    "from collections import namedtuple\r\n",
    "from model import NetworkCIFAR as Network\r\n",
    "from operations import Conv2d, NSTPConv2d, NConv2d, NLinear\r\n",
    "from utils import *\r\n",
    "from torch.utils.data.dataset import Subset\r\n",
    "import logging\r\n",
    "from nasnet_set import *\r\n",
    "from tqdm.notebook import tqdm\r\n",
    "\r\n",
    "net = eval('[2, 2, 0, 2, 1, 2, 0, 2, 2, 3, 2, 1, 2, 0, 0, 1, 1, 1, 2, 1, 1, 0, 3, 4, 3, 0, 3, 1]')\r\n",
    "# print(net)\r\n",
    "code = gen_code_from_list(net, node_num=int((len(net) / 4)))\r\n",
    "genotype = translator([code, code], max_node=int((len(net) / 4)))\r\n",
    "# print(genotype)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "device  = torch.device(f\"cuda:{0}\" if torch.cuda.is_available() else \"cpu\")\r\n",
    "# torch.cuda.set_device(args.gpu)\r\n",
    "if device != torch.device(\"cpu\"):\r\n",
    "    cudnn.benchmark = True\r\n",
    "    cudnn.enabled = True\r\n",
    "\r\n",
    "# logging.info('gpu device = %d' % args.gpu)\r\n",
    "# logging.info(\"args = %s\", args)\r\n",
    "\r\n",
    "model = Network(128, 10, 24, True, genotype)\r\n",
    "logging.info(\"param size = %fMB\", utils.count_parameters_in_MB(model))\r\n",
    "\r\n",
    "checkpoint = torch.load(\"./lanas_128_99.03\" + '/top1.pt', map_location=\"cpu\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "state_dict = checkpoint['model_state_dict']\r\n",
    "new_state_dict = model.state_dict()\r\n",
    "for key in state_dict.keys():\r\n",
    "    here = key.split(\".\")\r\n",
    "    this = \"\"\r\n",
    "    for i in here[:-1]:\r\n",
    "        this += (i + \".\")\r\n",
    "    this += (\"op.\" + here[-1])\r\n",
    "    if this in new_state_dict:\r\n",
    "        new_state_dict[this] = state_dict[key]\r\n",
    "    else:\r\n",
    "        new_state_dict[key] = state_dict[key]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "model.load_state_dict(new_state_dict)\r\n",
    "model = model.to(device)\r\n",
    "criterion = nn.CrossEntropyLoss().to(device)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "def infer(valid_queue, model, criterion, device):\r\n",
    "\r\n",
    "    objs = utils.AverageMeter()\r\n",
    "    top1 = utils.AverageMeter()\r\n",
    "    top5 = utils.AverageMeter()\r\n",
    "    # model.eval()\r\n",
    "\r\n",
    "    for step, (x, target) in enumerate(tqdm(valid_queue)):\r\n",
    "        x = x.to(device)\r\n",
    "        target = target.to(device)\r\n",
    "\r\n",
    "        with torch.no_grad():\r\n",
    "            logits, _ = model(x)\r\n",
    "            loss = criterion(logits, target)\r\n",
    "\r\n",
    "            prec1, prec5 = utils.accuracy(logits, target, topk=(1, 5))\r\n",
    "            n = x.size(0)\r\n",
    "            objs.update(loss.item(), n)\r\n",
    "            top1.update(prec1.item(), n)\r\n",
    "            top5.update(prec5.item(), n)\r\n",
    "\r\n",
    "    return top1.avg, objs.avg"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "\r\n",
    "CIFAR_MEAN = [0.49139968, 0.48215827, 0.44653124]\r\n",
    "CIFAR_STD = [0.24703233, 0.24348505, 0.26158768]\r\n",
    "\r\n",
    "valid_transform = transforms.Compose([\r\n",
    "    transforms.ToTensor(),\r\n",
    "    transforms.Normalize(CIFAR_MEAN, CIFAR_STD),\r\n",
    "])\r\n",
    "\r\n",
    "valid_queue = torch.utils.data.DataLoader(\r\n",
    "        dset.CIFAR10(root=\"~/Private/data\", train=False, transform=valid_transform),\r\n",
    "        batch_size=128, shuffle=True, num_workers=2, pin_memory=True)\r\n",
    "\r\n",
    "\r\n",
    "model.eval()\r\n",
    "model.clear_noise()\r\n",
    "# to_save = {}\r\n",
    "# state_dict = model.state_dict()\r\n",
    "# to_save[\"model_state_dict\"] = state_dict\r\n",
    "# torch.save(to_save, \"top1\")\r\n",
    "\r\n",
    "valid_acc, valid_obj = infer(valid_queue, model, criterion, device)\r\n",
    "print(valid_acc)"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "dc49e3c9714c4cae9a413d6a8c8fe619"
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=79.0), HTML(value='')))"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "99.04\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.4",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.4 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "04f3ce0738d928d74413a2b10d0d4c487f39bbf2ffd0e3f43a6ab028b956cd75"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}